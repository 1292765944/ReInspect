{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of ReInspect\n",
    "\n",
    "Evaluation for end-to-end people detection in crowded scenes.\n",
    "\n",
    "Let's start with importing the required files, seeding the random number generators and setting up the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-08-20 20:14:54 - GPU device 0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from utils.annolist import AnnotationLib as al\n",
    "\n",
    "import matplotlib; matplotlib.use('Agg', warn=False)\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import json\n",
    "import cv2\n",
    "from scipy.misc import imread\n",
    "from train import *\n",
    "from utils import load_data_mean, Rect, filter_rects\n",
    "from IPython import display\n",
    "%matplotlib inline\n",
    "\n",
    "# Make sure that caffe is on the python path:\n",
    "import apollocaffe\n",
    "config = json.load(open(\"config.json\", 'r'))\n",
    "config[\"solver\"][\"start_iter\"] = 250001\n",
    "\n",
    "random.seed(config[\"solver\"][\"random_seed\"])\n",
    "apollocaffe.set_random_seed(config[\"solver\"][\"random_seed\"])\n",
    "apollocaffe.set_device(0)\n",
    "apollocaffe.set_cpp_loglevel(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets load the data mean and the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_mean = load_data_mean(config[\"data\"][\"idl_mean\"], \n",
    "                           config[\"net\"][\"img_width\"], \n",
    "                           config[\"net\"][\"img_height\"], image_scaling=1.0)\n",
    "\n",
    "test_gen = load_idl_list(config[\"data\"][\"test_idl\"], data_mean, config[\"net\"], False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load the snapshot weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = apollocaffe.ApolloNet()\n",
    "forward(net, test_gen.next(), config[\"net\"], True)\n",
    "# net.draw_to_file(config[\"logging\"][\"schematic_path\"])\n",
    "net.load(\"/deep/u/ysavani/snapshots/brainwash/clean_450000.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the schematic. Double click on the network schematic to zoom in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9ee0f9e890>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schematic = imread(config[\"logging\"][\"schematic_path\"])\n",
    "plt.figure(figsize=(200,200))\n",
    "plt.imshow(schematic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now begin to run the model and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "annolist = al.AnnoList()\n",
    "net_config = config[\"net\"]\n",
    "pix_per_w = net_config[\"img_width\"]/net_config[\"grid_width\"]\n",
    "pix_per_h = net_config[\"img_height\"]/net_config[\"grid_height\"]\n",
    "for i in range(5):\n",
    "    inputs = test_gen.next()\n",
    "    bbox_list, conf_list = forward(net, inputs, net_config, True)\n",
    "    \n",
    "    img = inputs[\"raw\"]\n",
    "    png = inputs[\"imname\"]\n",
    "    all_rects = [[[] for x in range(net_config[\"grid_width\"])] for y in range(net_config[\"grid_height\"])]\n",
    "    for n in range(len(bbox_list)):\n",
    "        for k in range(net_config[\"grid_height\"] * net_config[\"grid_width\"]):\n",
    "            y = int(k / net_config[\"grid_width\"])\n",
    "            x = int(k % net_config[\"grid_width\"])\n",
    "            bbox = bbox_list[n][k]\n",
    "#             bbox = inputs[\"boxes\"][0,k,:,n,0]\n",
    "            conf = conf_list[n][k,1]\n",
    "            abs_cx = pix_per_w/2 + pix_per_w*x + int(bbox[0,0,0])\n",
    "            abs_cy = pix_per_h/2 + pix_per_h*y+int(bbox[1,0,0])\n",
    "            w = bbox[2,0,0]\n",
    "            h = bbox[3,0,0]\n",
    "            if conf > 0.7:\n",
    "                all_rects[y][x].append(Rect(abs_cx,abs_cy,w,h,conf - (0. * n)))\n",
    "    \n",
    "    acc_rects = []\n",
    "    acc_rects = filter_rects(all_rects, .5, acc_rects, config=net_config)\n",
    "    acc_rects = filter_rects(all_rects, .4, acc_rects, .6, config=net_config)\n",
    "    acc_rects = filter_rects(all_rects, .3, acc_rects, .5, config=net_config)\n",
    "    acc_rects = filter_rects(all_rects, .2, acc_rects, .4, config=net_config)\n",
    "    acc_rects = filter_rects(all_rects, .1, acc_rects, .3, config=net_config)\n",
    "    acc_rects = filter_rects(all_rects, .05, acc_rects, .2, config=net_config)\n",
    "\n",
    "    accepted_rects = acc_rects\n",
    "    \n",
    "    display = True\n",
    "    if display:\n",
    "        for rect in acc_rects:\n",
    "            assert rect.true_confidence <= rect.confidence\n",
    "            if rect.true_confidence < 0.1:\n",
    "                continue\n",
    "            cv2.rectangle(img, (rect.cx-int(rect.width/2), rect.cy-int(rect.height/2)), \n",
    "                          (rect.cx+int(rect.width/2), rect.cy+int(rect.height/2)), \n",
    "                                              (255,0,0), 2)\n",
    "     \n",
    "        plt.figure(figsize=(15,10))\n",
    "        plt.imshow(img)\n",
    "        \n",
    "    anno = al.Annotation()\n",
    "    anno.imageName = inputs[\"imname\"]\n",
    "    for rect in accepted_rects:\n",
    "        r = al.AnnoRect()\n",
    "        scale = 1.07 if (rect.width < 50 and rect.height < 50) else 1.0\n",
    "        r.x1 = rect.cx - rect.width/2.*scale\n",
    "        r.x2 = rect.cx + rect.width/2.*scale\n",
    "        r.y1 = rect.cy - rect.height/2.*scale\n",
    "        r.y2 = rect.cy + rect.height/2.*scale\n",
    "        r.score = rect.true_confidence\n",
    "        anno.rects.append(r)\n",
    "    annolist.append(anno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
